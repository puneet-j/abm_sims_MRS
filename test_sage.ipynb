{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x114352af0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import SAGEConv, GraphConv\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import pdb\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_dense_adj, subgraph, k_hop_subgraph\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.combine_nx_to_dataloader import GraphDataset\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels * 2)\n",
    "        self.conv3 = SAGEConv(hidden_channels * 2, hidden_channels)  # Additional hidden layer\n",
    "        self.conv4 = nn.Linear(hidden_channels, out_channels)  # Final Layer\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = self.conv4(x)\n",
    "        return x\n",
    "\n",
    "class GraphDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphDecoder, self).__init__()\n",
    "        # Assuming the encoded features are to be decoded back to original feature size\n",
    "        self.conv1 = SAGEConv(out_channels, hidden_channels * 2)\n",
    "        self.conv2 = SAGEConv(hidden_channels * 2, hidden_channels * 2)  # Mimic encoder complexity\n",
    "        self.conv3 = SAGEConv(hidden_channels * 2, hidden_channels)  # Additional hidden layer\n",
    "        self.conv4 = nn.Linear(hidden_channels, in_channels)  # Additional hidden layer to output size\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        # pdb.set_trace()\n",
    "        z = F.relu(self.conv1(z, edge_index))\n",
    "        z = F.relu(self.conv2(z, edge_index))\n",
    "        z = F.relu(self.conv3(z, edge_index))\n",
    "        z = self.conv4(z)\n",
    "        return z\n",
    "\n",
    "class MaskedGraphAutoencoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(MaskedGraphAutoencoder, self).__init__()\n",
    "        self.encoder = GraphEncoder(in_channels, hidden_channels, out_channels)\n",
    "        self.decoder = GraphDecoder(in_channels, hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x_masked = x #* mask\n",
    "        z = self.encoder(x_masked, edge_index)\n",
    "        x_reconstructed = self.decoder(z, edge_index)\n",
    "        return x_reconstructed, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    embeddings = []\n",
    "    origs = []\n",
    "    for data in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_x, embed = model(data[0][0], data[1][0])\n",
    "        origs.append(data[0][0])\n",
    "        # pdb.set_trace()\n",
    "        loss = loss_function(reconstructed_x, data[0][0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        embeddings.append(embed.detach())\n",
    "    return total_loss / len(data_loader), embeddings, origs\n",
    "\n",
    "# Assuming a loss function appropriate for node feature reconstruction, e.g., MSE for continuous features\n",
    "def loss_function(reconstructed_x, original_x):\n",
    "    return F.mse_loss(reconstructed_x, original_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2227\n",
      "Epoch 2, Loss: 0.1533\n",
      "Epoch 3, Loss: 0.1434\n",
      "Epoch 4, Loss: 0.1319\n",
      "Epoch 5, Loss: 0.1279\n",
      "Epoch 6, Loss: 0.1274\n",
      "Epoch 7, Loss: 0.1242\n",
      "Epoch 8, Loss: 0.1275\n",
      "Epoch 9, Loss: 0.1258\n",
      "Epoch 1, Loss: 0.2440\n",
      "Epoch 2, Loss: 0.1477\n",
      "Epoch 3, Loss: 0.1353\n",
      "Epoch 4, Loss: 0.4290\n",
      "Epoch 5, Loss: 0.4236\n",
      "Epoch 6, Loss: 0.4226\n",
      "Epoch 7, Loss: 0.2741\n",
      "Epoch 8, Loss: 0.1663\n",
      "Epoch 9, Loss: 0.1487\n",
      "Epoch 1, Loss: 0.2080\n",
      "Epoch 2, Loss: 0.2457\n",
      "Epoch 3, Loss: 0.4354\n",
      "Epoch 4, Loss: 0.3574\n",
      "Epoch 5, Loss: 0.2934\n",
      "Epoch 6, Loss: 0.2561\n",
      "Epoch 7, Loss: 0.3481\n",
      "Epoch 8, Loss: 0.4447\n",
      "Epoch 9, Loss: 0.4413\n",
      "Epoch 1, Loss: 0.2073\n",
      "Epoch 2, Loss: 0.1657\n",
      "Epoch 3, Loss: 0.1166\n",
      "Epoch 4, Loss: 0.1091\n",
      "Epoch 5, Loss: 0.1197\n",
      "Epoch 6, Loss: 0.1052\n",
      "Epoch 7, Loss: 0.1032\n",
      "Epoch 8, Loss: 0.1036\n",
      "Epoch 9, Loss: 0.1197\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # data = \n",
    "    # for node_features, edge_index, edge_features in dataloader:\n",
    "\n",
    "    # pdb.set_trace()\n",
    "    # cuda_available = torch.cuda.is_available()\n",
    "    # device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
    "    folder_graph = './graphs/graphsage_graph/single_graphs/'\n",
    "    fname = 'graph_list_with_features.pth'\n",
    "\n",
    "    hC = 64\n",
    "    inC = 40 #len(G.nodes[0]['x'])\n",
    "    # print('dimension of nodes: ',inC)\n",
    "    '''\n",
    "    print(f\"radius: {nx.radius(G)}\")\n",
    "    print(f\"diameter: {nx.diameter(G)}\")\n",
    "    # print(f\"eccentricity: {nx.eccentricity(G)}\")\n",
    "    print(f\"center: {nx.center(G)}\")\n",
    "    # print(f\"periphery: {nx.periphery(G)}\")\n",
    "    # print(f\"density: {nx.density(G)}\")\n",
    "    print(f\"max degree: {np.max(G.degree())}\")\n",
    "    '''\n",
    "    \n",
    "    # trainG, testG = get_test_train(G, num_test_nodes=0)\n",
    "    # Convert networkx graph to PyTorch Geometric graph\n",
    "    # trainPyG = networkx_to_pyg_graph(trainG, 'x', 'weight')\n",
    "    # pdb.set_trace()\n",
    "    # subgraphs = create_subgraphs(pyg_graph, num_subgraphs=1, num_hops=2)\n",
    "    # pdb.set_trace()\n",
    "    # testPyG = get_test_train(testG, 'x')\n",
    "    # data_loader = DataLoader(subgraphs, batch_size=1, shuffle=True)\n",
    "    # pdb.set_trace()\n",
    "    graph_list = torch.load(fname)\n",
    "    # pdb.set_trace()\n",
    "    dataset = GraphDataset(graph_list)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    actuals = []\n",
    "    final_loss = []\n",
    "    embeddings = []\n",
    "    for outchannels in range(2,6):\n",
    "        model = MaskedGraphAutoencoder(in_channels=inC, hidden_channels=hC, out_channels=outchannels)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "        losses = []\n",
    "        embeds = []\n",
    "        acts = []\n",
    "        for epoch in range(1, 10):  # Number of epochs\n",
    "            loss, embeds, orig = train(model, dataloader, optimizer)\n",
    "            embeds.append(embeds)\n",
    "            acts.append(orig)\n",
    "            print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
    "            losses.append(loss)\n",
    "        embeddings.append(embeds)\n",
    "        final_loss.append(losses)\n",
    "        actuals.append(acts)\n",
    "        # Assuming encoder and decoder are your model's components\n",
    "        encoder_state_dict = model.encoder.state_dict()\n",
    "        decoder_state_dict = model.decoder.state_dict()\n",
    "\n",
    "        # Save the state dictionaries\n",
    "        torch.save(encoder_state_dict, 'encoder_state_dict'+str(outchannels)+'.pth')\n",
    "        torch.save(decoder_state_dict, 'decoder_state_dict'+str(outchannels)+'.pth')\n",
    "\n",
    "    # print(final_loss)\n",
    "    np.save('gaelossarray_sage_no_weights_3_5_with_embeds.npy', final_loss)\n",
    "    # pdb.set_trace()\n",
    "    fl = open('embeddings_3_5.pickle', 'wb')\n",
    "    pickle.dump(embeddings, fl)\n",
    "    fl.close()\n",
    "\n",
    "    fl = open('actuals_3_5.pickle', 'wb')\n",
    "    pickle.dump(actuals, fl)\n",
    "    fl.close()\n",
    "\n",
    "\n",
    "    # np.save('embeddings.npy', embeddings.numpy()) \n",
    "    # print(range(5,20))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "677420"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del encoder_state_dict\n",
    "del decoder_state_dict\n",
    "del dataloader\n",
    "del dataset\n",
    "del embeddings\n",
    "del embeds\n",
    "del graph_list \n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "564"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "del final_loss\n",
    "del losses\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dict = torch.load('encoder_state_dict3.pth')\n",
    "decoder_dict = torch.load('decoder_state_dict3.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "in_channels = 40\n",
    "hidden_channels = 64\n",
    "out_channels = 3\n",
    "GAE = MaskedGraphAutoencoder(in_channels, hidden_channels, out_channels)\n",
    "GAE.encoder.load_state_dict(encoder_dict)\n",
    "GAE.decoder.load_state_dict(decoder_dict)\n",
    "\n",
    "fil =  open('embeddings_3_5.pickle', 'rb')\n",
    "embed = pickle.load(fil)   \n",
    "fil.close() \n",
    "emb = embed[1]\n",
    "# print(len(emb[0]))\n",
    "fil =  open('actuals_3_5.pickle', 'rb')\n",
    "original = pickle.load(fil)   \n",
    "fil.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6899, 3.8092],\n",
      "        [0.8655, 4.8483],\n",
      "        [0.6520, 3.5848],\n",
      "        [0.6274, 3.4393],\n",
      "        [0.6382, 3.5034],\n",
      "        [0.6238, 3.4181],\n",
      "        [0.5995, 3.2746],\n",
      "        [0.8384, 4.6879],\n",
      "        [0.8023, 4.4742],\n",
      "        [0.5978, 3.2640],\n",
      "        [0.4694, 2.5042],\n",
      "        [0.5848, 3.1874],\n",
      "        [0.4171, 2.1951],\n",
      "        [0.5699, 3.0993],\n",
      "        [0.7785, 4.3333],\n",
      "        [0.7704, 4.2854],\n",
      "        [0.6392, 3.5094],\n",
      "        [0.6047, 3.3048],\n",
      "        [0.5704, 3.1022],\n",
      "        [0.5622, 3.0537],\n",
      "        [0.3867, 2.0147],\n",
      "        [0.3390, 1.7328],\n",
      "        [0.2493, 1.2020],\n",
      "        [0.3571, 1.8396],\n",
      "        [0.3441, 1.7630],\n",
      "        [0.3353, 1.7109],\n",
      "        [0.7546, 4.1923],\n",
      "        [0.3446, 1.7656],\n",
      "        [0.7442, 4.1306],\n",
      "        [0.3781, 1.9643],\n",
      "        [0.3351, 1.7095],\n",
      "        [0.2432, 1.1656],\n",
      "        [0.5398, 2.9212],\n",
      "        [0.3317, 1.6898],\n",
      "        [0.7371, 4.0883],\n",
      "        [0.5623, 3.0539],\n",
      "        [0.3877, 2.0208],\n",
      "        [0.3292, 1.6749],\n",
      "        [0.2373, 1.1311],\n",
      "        [0.7080, 3.9166],\n",
      "        [0.5990, 3.2711],\n",
      "        [0.2322, 1.1005],\n",
      "        [0.3214, 1.6284],\n",
      "        [0.3154, 1.5933],\n",
      "        [0.3223, 1.6337],\n",
      "        [0.2313, 1.0954],\n",
      "        [0.3143, 1.5863],\n",
      "        [0.2201, 1.0289],\n",
      "        [0.3005, 1.5051],\n",
      "        [0.2202, 1.0295],\n",
      "        [0.2172, 1.0119],\n",
      "        [0.1820, 0.8036],\n",
      "        [0.1479, 0.6019],\n",
      "        [0.1972, 0.8938],\n",
      "        [0.2219, 1.0395],\n",
      "        [0.1836, 0.8132],\n",
      "        [0.2132, 0.9882],\n",
      "        [0.2055, 0.9429],\n",
      "        [0.1984, 0.9005],\n",
      "        [0.1885, 0.8422],\n",
      "        [0.1776, 0.7775],\n",
      "        [0.1912, 0.8578],\n",
      "        [0.1730, 0.7502]])\n",
      "tensor([ 0.0000, -0.1000,  0.0000,  0.5410,  0.0000, -0.1000,  0.0000,  0.5410,\n",
      "         0.0000, -0.1000,  0.0000,  0.5410,  0.0000, -0.1000,  0.0000,  0.5410,\n",
      "         0.0000, -0.1000,  0.0000,  0.5410,  0.0000, -0.1000,  0.0000,  0.5410,\n",
      "         2.0000, -0.1000,  0.0000,  0.5410,  2.0000, -0.1000,  0.0000,  0.5410,\n",
      "         3.0000, -0.1000,  0.0000,  0.5410,  4.0000,  1.0000,  1.0000,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "e = emb[0][0].tolist()\n",
    "print(emb[0])\n",
    "# print(e[0].tolist())\n",
    "print(original[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty((2,1), dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000, -0.1500,  0.0000,  0.5810,  0.0000, -0.1500,  0.0000,\n",
      "           0.5810,  0.0000, -0.1500,  0.0000,  0.5810,  0.0000, -0.1500,\n",
      "           0.0000,  0.5810,  0.0000, -0.1500,  0.0000,  0.5810,  0.0000,\n",
      "          -0.1500,  0.0000,  0.5810,  3.0000, -0.1500,  0.0000,  0.5810,\n",
      "           3.0000, -0.1500,  0.0000,  0.5810,  3.0000, -0.1500,  0.0000,\n",
      "           0.5810,  3.0000, -0.1500,  0.0000,  0.5810]]])\n"
     ]
    }
   ],
   "source": [
    "original_input = torch.tensor([[original[0][0][0][0].tolist()]])\n",
    "print(original_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000, -0.1500,  0.0000,  0.5810,  0.0000, -0.1500,  0.0000,\n",
      "           0.5810,  0.0000, -0.1500,  0.0000,  0.5810,  0.0000, -0.1500,\n",
      "           0.0000,  0.5810,  0.0000, -0.1500,  0.0000,  0.5810,  0.0000,\n",
      "          -0.1500,  0.0000,  0.5810,  3.0000, -0.1500,  0.0000,  0.5810,\n",
      "           3.0000, -0.1500,  0.0000,  0.5810,  3.0000, -0.1500,  0.0000,\n",
      "           0.5810,  3.0000, -0.1500,  0.0000,  0.5810]]])\n",
      "tensor([[[0.0000, 0.0000, 6.6842]]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# input = torch.tensor([[e]])\n",
    "result = GAE.encoder(original_input, torch.empty((2,0), dtype=torch.int64))\n",
    "print(original_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.5841, 0.0000]]])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.3101, 0.0000, 0.0000, 0.6715,\n",
      "          0.5578, 0.0000, 0.0000, 0.6770, 0.8943, 0.0000, 0.0000, 0.6568,\n",
      "          1.3684, 0.0000, 0.0000, 0.0000, 1.8016, 0.0000, 0.0000, 0.6539,\n",
      "          2.2844, 0.0000, 0.0000, 0.6016, 2.6953, 0.0000, 0.0000, 0.5784,\n",
      "          3.4477, 0.2503, 0.3357, 0.0000, 4.9098, 1.0378, 1.0295, 0.0000]]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.tensor([[e]])\n",
    "result = GAE.decoder(input, torch.empty((2,0), dtype=torch.int64))\n",
    "print(input)\n",
    "print(result)\n",
    "# for i in range(0,5):\n",
    "#     print(e[i])\n",
    "#     print(result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.0000, 0.5841, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.3101, 0.0000, 0.0000, 0.6715, 0.5578,\n",
      "        0.0000, 0.0000, 0.6770, 0.8943, 0.0000, 0.0000, 0.6568, 1.3684, 0.0000,\n",
      "        0.0000, 0.0000, 1.8016, 0.0000, 0.0000, 0.6539, 2.2844, 0.0000, 0.0000,\n",
      "        0.6016, 2.6953, 0.0000, 0.0000, 0.5784, 3.4477, 0.2503, 0.3357, 0.0000,\n",
      "        4.9098, 1.0378, 1.0295, 0.0000], grad_fn=<SelectBackward0>)\n",
      "tensor([0.0000, 0.0000, 0.1196, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8237, 0.0000,\n",
      "        0.0000, 0.0000, 0.8369, 0.0000, 0.0000, 0.0000, 0.7865, 0.3559, 0.0000,\n",
      "        0.0000, 0.0000, 0.7825, 0.0000, 0.0000, 0.7615, 1.6295, 0.0000, 0.0000,\n",
      "        0.6953, 2.0372, 0.0000, 0.0000, 0.7430, 2.3667, 0.0000, 0.0000, 0.0000,\n",
      "        4.7823, 1.0200, 0.9818, 0.0000], grad_fn=<SelectBackward0>)\n",
      "tensor([0.0000, 0.0000, 0.1196, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8237, 0.0000,\n",
      "        0.0000, 0.0000, 0.8369, 0.0000, 0.0000, 0.0000, 0.7865, 0.3559, 0.0000,\n",
      "        0.0000, 0.0000, 0.7825, 0.0000, 0.0000, 0.7615, 1.6295, 0.0000, 0.0000,\n",
      "        0.6953, 2.0372, 0.0000, 0.0000, 0.7430, 2.3667, 0.0000, 0.0000, 0.0000,\n",
      "        4.7823, 1.0200, 0.9818, 0.0000], grad_fn=<SelectBackward0>)\n",
      "tensor([0.0000, 0.0000, 0.1196, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8237, 0.0000,\n",
      "        0.0000, 0.0000, 0.8369, 0.0000, 0.0000, 0.0000, 0.7865, 0.3559, 0.0000,\n",
      "        0.0000, 0.0000, 0.7825, 0.0000, 0.0000, 0.7615, 1.6295, 0.0000, 0.0000,\n",
      "        0.6953, 2.0372, 0.0000, 0.0000, 0.7430, 2.3667, 0.0000, 0.0000, 0.0000,\n",
      "        4.7823, 1.0200, 0.9818, 0.0000], grad_fn=<SelectBackward0>)\n",
      "tensor([0.0000, 0.0000, 0.1196, 0.0000])\n",
      "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8237, 0.0000,\n",
      "        0.0000, 0.0000, 0.8369, 0.0000, 0.0000, 0.0000, 0.7865, 0.3559, 0.0000,\n",
      "        0.0000, 0.0000, 0.7825, 0.0000, 0.0000, 0.7615, 1.6295, 0.0000, 0.0000,\n",
      "        0.6953, 2.0372, 0.0000, 0.0000, 0.7430, 2.3667, 0.0000, 0.0000, 0.0000,\n",
      "        4.7823, 1.0200, 0.9818, 0.0000], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "result = GAE.decoder(e, torch.empty((2,0), dtype=torch.int64))\n",
    "for i in range(0,5):\n",
    "    print(e[i])\n",
    "    print(result[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
