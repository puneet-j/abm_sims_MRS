{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch import nn\n",
    "# import torch_geometric\n",
    "from torch_geometric.nn import SAGEConv\n",
    "# from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import pdb\n",
    "from torch_geometric.loader import DataLoader\n",
    "# import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# from torch_geometric.utils import to_dense_adj, subgraph, k_hop_subgraph\n",
    "import matplotlib.pyplot as plt\n",
    "from tools.combine_nx_to_dataloader import GraphDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=40, encoded_dim=3):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        # Adjusted to include two additional layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=3, stride=2, padding=1),  # input is 1 channel, output is 16 channels\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(16, 32, kernel_size=3, stride=2, padding=1),  # Further reduces the dimension\n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(),  # Flatten the output to feed into a linear layer for the encoded representation\n",
    "            nn.Linear(320, encoded_dim)  # Adjust the input features to match the output of the last conv layer\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoded_dim, 320),  # First, expand to the flattened size before the last conv layer\n",
    "            nn.ReLU(True),\n",
    "            nn.Unflatten(1, (32, 10)),  # Unflatten to shape that matches the encoder's last conv output\n",
    "            nn.ConvTranspose1d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose1d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Ensure output values are between 0 and 1\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add a channel dimension\n",
    "        z = self.encoder(x)\n",
    "        recon = self.decoder(z)\n",
    "        recon = recon.squeeze(1)\n",
    "        return recon, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSparseVAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dims=[400, 200], latent_dim=20, sparsity_target=0.1, sparsity_weight=1e-3):\n",
    "        super(DeepSparseVAE, self).__init__()\n",
    "        self.sparsity_target = sparsity_target\n",
    "        self.sparsity_weight = sparsity_weight\n",
    "\n",
    "        # Encoder\n",
    "        encoder_layers = []\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            encoder_layers.append(nn.Linear(hidden_dims[i], hidden_dims[i+1]))\n",
    "            encoder_layers.append(nn.ReLU(True))\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        self.fc_mu = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dims[-1], latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_layers = []\n",
    "        hidden_dims_reversed = hidden_dims[::-1]\n",
    "        for i in range(len(hidden_dims_reversed) - 1):\n",
    "            decoder_layers.append(nn.Linear(hidden_dims_reversed[i], hidden_dims_reversed[i+1]))\n",
    "            decoder_layers.append(nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(*decoder_layers, nn.Linear(hidden_dims_reversed[-1], input_dim), nn.Sigmoid())\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h), h\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar, h = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar, h\n",
    "\n",
    "    def loss_function(self, recon_x, x, mu, logvar, h):\n",
    "        BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "        sparsity_loss = F.kl_div(h.mean(0).log(), torch.tensor([self.sparsity_target]).to(h.device), reduction='batchmean')\n",
    "        sparsity_loss *= self.sparsity_weight\n",
    "        return BCE + KLD + sparsity_loss\n",
    "\n",
    "# Example instantiation with deeper architecture\n",
    "model = DeepSparseVAE(input_dim=40, hidden_dims=[400, 200, 100], latent_dim=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "node_list = []\n",
    "folder_graph = './graphs/graphsage_graph/single_graphs/'\n",
    "metadata_file = folder_graph + 'metadata.csv'\n",
    "succTimeFiles = folder_graph + 'graphMetadata.csv'\n",
    "\n",
    "files = os.listdir(folder_graph)\n",
    "files = [file for file in files if file.endswith('.pickle')]\n",
    "for file in files:\n",
    "    fil =  open(folder_graph+file, 'rb')\n",
    "    G = pickle.load(fil)\n",
    "    fil.close()\n",
    "    # print(G.nodes[0])\n",
    "    for node in G.nodes(data=True):\n",
    "        # print(node[1]['x'])\n",
    "        # break\n",
    "        node_list.append(node[1]['x'])\n",
    "    # break\n",
    "\n",
    "# dataset = GraphDataset(graph_list)\n",
    "# dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Save the graph list for later use, similar to the previous example\n",
    "torch.save(node_list, 'nodelist.pth')\n",
    "\n",
    "# # Example of iterating over the DataLoader in a training loop\n",
    "# for node_features, edge_index, edge_features in dataloader:\n",
    "#     # Use these in your GAE model\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda_available else \"cpu\")\n",
    "folder_graph = './graphs/graphsage_graph/single_graphs/'\n",
    "fname = 'nodelist.pth'\n",
    "nodelist = torch.load(fname)\n",
    "data_nodes = torch.tensor(nodelist, dtype=torch.float32)\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Return the item at the given index\n",
    "        return self.data[index]\n",
    "dataset = CustomDataset(data_nodes)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m):\n\u001b[1;32m     17\u001b[0m     total_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mfor\u001b[39;00m input_vector \u001b[39min\u001b[39;00m dataloader:  \u001b[39m# Assuming the dataset returns a tuple where the first element is the input\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m         output, embed \u001b[39m=\u001b[39m autoencoder(input_vector)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "# Initialize the autoencoder\n",
    "generated_embeds = []\n",
    "losses = []\n",
    "for ed in range(3,10):\n",
    "    autoencoder = DeepSparseVAE(input_dim=40, hidden_dims=[400, 200, 100], latent_dim=ed)\n",
    "    # Example of a loss function and optimizer\n",
    "    criterion = nn.MSELoss() # Mean Squared Error Loss\n",
    "    optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.1) # Adam optimizer\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "    # d = [a for a in dataloader]\n",
    "    # print(d)\n",
    "    loss_vec = []\n",
    "    embed_vec = []\n",
    "    for epoch in range(1, 50):\n",
    "        total_loss = 0.0\n",
    "        for input_vector in dataloader:  # Assuming the dataset returns a tuple where the first element is the input\n",
    "            optimizer.zero_grad()\n",
    "            output, embed = autoencoder(input_vector)\n",
    "            # print(input_vector[0], '\\n', output)\n",
    "            loss = criterion(output, input_vector)  # Assuming target is the same as input\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # Average loss for this epoch\n",
    "        epoch_loss = total_loss / len(dataloader)\n",
    "        embed_vec.append(embed)\n",
    "        loss_vec.append(epoch_loss)\n",
    "        # Step the scheduler based on the epoch loss\n",
    "        scheduler.step(epoch_loss)\n",
    "        gc.collect()\n",
    "        # if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {epoch_loss:.4f}')\n",
    "    losses.append(loss_vec)\n",
    "    generated_embeds.append(embed_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# del nodelist\n",
    "# del data_nodes\n",
    "# del dataloader\n",
    "# del dataset\n",
    "# del node_list\n",
    "# del autoencoder\n",
    "gc.collect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
