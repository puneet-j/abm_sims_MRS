{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "from torch import nn\n",
    "# import torch_geometric\n",
    "from torch_geometric.nn import SAGEConv\n",
    "# from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import pdb\n",
    "# from torch_geometric.loader import DataLoader\n",
    "# import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# from torch_geometric.utils import to_dense_adj, subgraph, k_hop_subgraph\n",
    "import matplotlib.pyplot as plt\n",
    "# from tools.combine_nx_to_dataloader import GraphDataset\n",
    "\n",
    "\n",
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels * 2)\n",
    "        # self.conv3 = SAGEConv(hidden_channels * 2, hidden_channels * 2)  # Additional hidden layer\n",
    "        self.conv3 = SAGEConv(hidden_channels * 2, out_channels)  # Final Layer\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        try:\n",
    "            x = F.relu(self.conv1(x, edge_index))\n",
    "            x = F.relu(self.conv2(x, edge_index))\n",
    "            x = F.relu(self.conv3(x, edge_index))\n",
    "            # x = self.conv3(x, edge_index)\n",
    "            return x\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pdb.set_trace()\n",
    "\n",
    "class GraphDecoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GraphDecoder, self).__init__()\n",
    "        # Assuming the encoded features are to be decoded back to original feature size\n",
    "        self.conv1 = SAGEConv(out_channels, hidden_channels * 2)\n",
    "        self.conv2 = SAGEConv(hidden_channels * 2, hidden_channels * 2)  # Mimic encoder complexity\n",
    "        # self.conv3 = SAGEConv(hidden_channels * 2, hidden_channels)  # Additional hidden layer\n",
    "        self.conv3 = SAGEConv(hidden_channels * 2, in_channels)  # Additional hidden layer to output size\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        z = F.relu(self.conv1(z, edge_index))\n",
    "        z = F.relu(self.conv2(z, edge_index))\n",
    "        z = F.relu(self.conv3(z, edge_index))\n",
    "        # z = self.conv4(z, edge_index)\n",
    "        return z\n",
    "\n",
    "class MaskedGraphAutoencoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(MaskedGraphAutoencoder, self).__init__()\n",
    "        self.encoder = GraphEncoder(in_channels, hidden_channels, out_channels)\n",
    "        self.decoder = GraphDecoder(in_channels, hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x_masked = x #* mask\n",
    "        z = self.encoder(x_masked, edge_index)\n",
    "        x_reconstructed = self.decoder(z, edge_index)\n",
    "        return x_reconstructed, z\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = torch.load('encoder2.pth')\n",
    "decoder = torch.load('decoder2.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil =  open('embeddings.pickle', 'rb')\n",
    "embed = pickle.load(fil)   \n",
    "fil.close() \n",
    "emb = embed[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[0][0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got -2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[39m=\u001b[39m decoder(torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m], dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mint), torch\u001b[39m.\u001b[39;49mtensor([[\u001b[39m0\u001b[39;49m],[\u001b[39m0\u001b[39;49m]], dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mint64))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 51\u001b[0m, in \u001b[0;36mGraphDecoder.forward\u001b[0;34m(self, z, edge_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, z, edge_index):\n\u001b[0;32m---> 51\u001b[0m     z \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(z, edge_index))\n\u001b[1;32m     52\u001b[0m     z \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(z, edge_index))\n\u001b[1;32m     53\u001b[0m     z \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv3(z, edge_index))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch_geometric/nn/conv/sage_conv.py:130\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    127\u001b[0m     x \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x[\u001b[39m0\u001b[39m])\u001b[39m.\u001b[39mrelu(), x[\u001b[39m1\u001b[39m])\n\u001b[1;32m    129\u001b[0m \u001b[39m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, size\u001b[39m=\u001b[39;49msize)\n\u001b[1;32m    131\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_l(out)\n\u001b[1;32m    133\u001b[0m x_r \u001b[39m=\u001b[39m x[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch_geometric/nn/conv/message_passing.py:455\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m decomp_args:\n\u001b[1;32m    453\u001b[0m         kwargs[arg] \u001b[39m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[0;32m--> 455\u001b[0m coll_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_user_args, edge_index, size,\n\u001b[1;32m    456\u001b[0m                           kwargs)\n\u001b[1;32m    458\u001b[0m msg_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[1;32m    459\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_pre_hooks\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch_geometric/nn/conv/message_passing.py:324\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data[\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m dim], Tensor):\n\u001b[0;32m--> 324\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_size(size, \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m dim, data[\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m dim])\n\u001b[1;32m    325\u001b[0m     data \u001b[39m=\u001b[39m data[dim]\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Tensor):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch_geometric/nn/conv/message_passing.py:237\u001b[0m, in \u001b[0;36mMessagePassing._set_size\u001b[0;34m(self, size, dim, src)\u001b[0m\n\u001b[1;32m    235\u001b[0m the_size \u001b[39m=\u001b[39m size[dim]\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m the_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     size[dim] \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39;49msize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim)\n\u001b[1;32m    238\u001b[0m \u001b[39melif\u001b[39;00m the_size \u001b[39m!=\u001b[39m src\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim):\n\u001b[1;32m    239\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m         (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEncountered tensor with size \u001b[39m\u001b[39m{\u001b[39;00msrc\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim)\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    241\u001b[0m          \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdimension \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim\u001b[39m}\u001b[39;00m\u001b[39m, but expected size \u001b[39m\u001b[39m{\u001b[39;00mthe_size\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
     ]
    }
   ],
   "source": [
    "result = decoder(torch.tensor([0, 0], dtype=torch.float32), torch.tensor([[0],[0]], dtype=torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9305, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9305, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9305, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9305, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9305, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9305, 0.0000]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
